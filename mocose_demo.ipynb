{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0bab27",
   "metadata": {},
   "source": [
    "# 1. Training Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cc9be",
   "metadata": {},
   "source": [
    "## Step 0. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f73abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk #, load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from mocose import *\n",
    "from transformers import BertConfig\n",
    "from mocose_tools import MoCoSETrainer\n",
    "from transformers.trainer import TrainingArguments\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37711859",
   "metadata": {},
   "source": [
    "## Step 1.1. Load Dataset from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2671fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_size = 64\n",
    "train_dataset = load_from_disk(\"F:\\\\Models\\\\temp\\\\wiki_for_sts_32\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e8016",
   "metadata": {},
   "source": [
    "## Step 1.2. Load Dataset with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6709bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = load_dataset(\"text\", data_files=\"F:\\\\Experiment\\MoCoSE\\codes\\data\\wiki1m_for_simcse.txt\", cache_dir=\"F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\data\")\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare_features(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4654fdc",
   "metadata": {},
   "source": [
    "## Setp 1.3. init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a1aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()\n",
    "config.out_size=768\n",
    "config.mlp_layers=2\n",
    "config.proj_layers=1\n",
    "\n",
    "config.fgsm = 5e-9\n",
    "config.embedding_drop_prob = 0.1\n",
    "config.token_drop_prob = 0\n",
    "config.feature_drop_prob = 0\n",
    "config.token_shuffle = False\n",
    "config.contextual_wordembs_aug = False\n",
    "\n",
    "config.age_test = False\n",
    "\n",
    "config.K = 256\n",
    "config.K_start = 128\n",
    "config.ema_decay = 0.75\n",
    "\n",
    "\n",
    "config.neg_queue_slice_span = 256 # euqal to batch size, won't work if age_test=False\n",
    "\n",
    "with open(r'F:\\Experiment\\MoCoSE\\codes\\pretrained_bert\\bert-base-uncased\\vocab.txt','r',encoding='utf8') as f:\n",
    "    test_untokenizer = f.readlines()\n",
    "untokenizer = [i[:-1] for i in test_untokenizer]\n",
    "config.untokenizer = untokenizer\n",
    "\n",
    "model = MoCoSEModel(config)\n",
    "model.online_embeddings.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\embeddings.pth'))\n",
    "model.online_encoder.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\encoder.pth'))\n",
    "model.online_pooler.dense.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\pooler_dense.pth'))\n",
    "\n",
    "model.prepare()\n",
    "model = model.cuda()\n",
    "\n",
    "non_optimizer_list = [model.target_encoder,model.target_pooler]\n",
    "for layer in non_optimizer_list:\n",
    "    for para in layer.parameters():\n",
    "        para.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57884f",
   "metadata": {},
   "source": [
    "### Setp 1.3.1 add calculation methods of aliment and uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3bd6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_loss(x, y, alpha=2):    \n",
    "    return (x - y).norm(p=2, dim=1).pow(alpha).mean()\n",
    "\n",
    "def uniform_loss(x, t=2):\n",
    "    return torch.pdist(x, p=2).pow(2).mul(-t).exp().mean().log()\n",
    "\n",
    "def get_pair_emb(model, input_ids, attention_mask,token_type_ids):    \n",
    "    outputs = model(input_ids = input_ids.cuda(),attention_mask=attention_mask.cuda(),token_type_ids=token_type_ids.cuda(),sent_emb=True)\n",
    "    pooler_output = outputs.last_hidden_state[:,0]     \n",
    "    #pooler_output = outputs.pooler_output\n",
    "    z1, z2 = pooler_output[:batch_size], pooler_output[batch_size:]\n",
    "    return z1.cpu(),z2.cpu()\n",
    "\n",
    "def get_align(model, dataloader):\n",
    "    align_all = []\n",
    "    with torch.no_grad():        \n",
    "        for data in dataloader:\n",
    "            input_ids = torch.cat((data['input_ids'][0],data['input_ids'][1]))\n",
    "            attention_mask = torch.cat((data['attention_mask'][0],data['attention_mask'][1]))\n",
    "            token_type_ids = torch.cat((data['token_type_ids'][0],data['token_type_ids'][1]))\n",
    "\n",
    "            z1,z2 = get_pair_emb(model, input_ids, attention_mask, token_type_ids)  \n",
    "            z1 = F.normalize(z1,dim=1)\n",
    "            z2 = F.normalize(z2,dim=1)\n",
    "            align_all.append(align_loss(z1, z2))\n",
    "            \n",
    "    return align_all\n",
    "    \n",
    "def get_unif(model, dataloader):\n",
    "    unif_all = []\n",
    "    with torch.no_grad():        \n",
    "        for data in dataloader:\n",
    "            input_ids = torch.cat((data['input_ids'][0],data['input_ids'][1]))\n",
    "            attention_mask = torch.cat((data['attention_mask'][0],data['attention_mask'][1]))\n",
    "            token_type_ids = torch.cat((data['token_type_ids'][0],data['token_type_ids'][1]))\n",
    "            z1,z2 = get_pair_emb(model, input_ids, attention_mask, token_type_ids)   \n",
    "            #z = torch.cat((z1,z2))\n",
    "            z = z1\n",
    "            z = F.normalize(z,p=2,dim=1)\n",
    "            unif_all.append(uniform_loss(z, t=2))\n",
    "            \n",
    "    return unif_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00922632",
   "metadata": {},
   "source": [
    "## Step 1.4. set train arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d83411",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = 'F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\',\n",
    "    evaluation_strategy   = \"steps\",\n",
    "    eval_steps            = 175,\n",
    "    learning_rate         = 3e-5,\n",
    "    num_train_epochs      = 1.0,\n",
    "    weight_decay          = 1e-6,\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size  = 256,\n",
    "    dataloader_drop_last = True,\n",
    ")\n",
    "trainer = MoCoSETrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf04e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dataset = load_from_disk(\"F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\data\\\\uniform_align_data\\\\stsb_pos\")\n",
    "pos_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "pos_loader = DataLoader(pos_dataset, batch_size = batch_size, drop_last = True)\n",
    "\n",
    "all_dataset = load_from_disk(\"F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\data\\\\uniform_align_data\\\\stsb_all\")\n",
    "all_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "all_loader = DataLoader(all_dataset, batch_size = batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef622c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 995447\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3888\n",
      "  5%|▍         | 175/3888 [03:16<1:08:27,  1.11s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 29.77 | 48.80 | 41.32 | 51.11 | 57.12 |    32.64     |      46.65      | 43.92 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 43.91625 \n",
      "max acc  43.91625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 350/3888 [07:08<1:04:34,  1.10s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 56.44 | 69.74 | 61.81 | 73.13 | 69.91 |    64.62     |      68.67      | 66.33 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 66.33125 \n",
      "max acc  66.33125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3888 [10:31<1:00:54,  1.08s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5761, 'learning_rate': 2.6141975308641973e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\special_tokens_map.json\n",
      " 14%|█▎        | 525/3888 [11:00<1:00:26,  1.08s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 62.00 | 75.53 | 67.46 | 77.24 | 74.67 |    71.90     |      72.27      | 71.58 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 71.58125000000001 \n",
      "max acc  71.58125000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 700/3888 [14:50<57:48,  1.09s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 64.15 | 77.48 | 69.29 | 78.53 | 76.17 |    74.38     |      73.04      | 73.29 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 73.29125 \n",
      "max acc  73.29125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 875/3888 [18:44<54:29,  1.09s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.38 | 78.77 | 70.51 | 80.08 | 77.02 |    75.93     |      73.36      | 74.44 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 74.43625 \n",
      "max acc  74.43625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3888 [21:39<51:36,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0196, 'learning_rate': 2.2283950617283953e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\special_tokens_map.json\n",
      " 27%|██▋       | 1050/3888 [22:35<51:08,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 66.85 | 79.79 | 71.91 | 81.20 | 78.06 |    77.27     |      73.16      | 75.46 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 75.4625 \n",
      "max acc  75.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1225/3888 [26:25<48:45,  1.10s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 67.96 | 80.66 | 72.60 | 81.98 | 78.54 |    78.16     |      73.01      | 76.13 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.13 \n",
      "max acc  76.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1400/3888 [30:14<45:06,  1.09s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.48 | 80.96 | 73.00 | 82.41 | 78.80 |    78.53     |      72.66      | 76.41 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.40625 \n",
      "max acc  76.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1500/3888 [32:48<44:23,  1.12s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0096, 'learning_rate': 1.8425925925925926e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\special_tokens_map.json\n",
      " 41%|████      | 1575/3888 [34:12<42:57,  1.11s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.80 | 80.94 | 73.40 | 82.58 | 78.79 |    78.72     |      72.58      | 76.54 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.54375 \n",
      "max acc  76.54375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1750/3888 [38:02<38:26,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.40 | 81.41 | 73.63 | 82.75 | 79.08 |    78.89     |      72.19      | 76.76 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.76374999999999 \n",
      "max acc  76.76374999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1925/3888 [41:52<35:32,  1.09s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.46 | 81.50 | 73.77 | 82.77 | 79.22 |    78.97     |      72.17      | 76.84 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.83749999999999 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 2000/3888 [43:54<34:09,  1.09s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0064, 'learning_rate': 1.4567901234567902e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\special_tokens_map.json\n",
      " 54%|█████▍    | 2100/3888 [45:45<33:34,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.46 | 81.43 | 73.90 | 82.71 | 79.18 |    78.80     |      71.92      | 76.77 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.77125 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 2275/3888 [49:35<29:02,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.26 | 81.07 | 73.64 | 82.51 | 79.12 |    78.64     |      71.96      | 76.60 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.6 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2450/3888 [53:23<25:40,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.44 | 81.08 | 73.82 | 82.58 | 79.19 |    78.77     |      71.77      | 76.66 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.66375 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2500/3888 [54:55<24:41,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0051, 'learning_rate': 1.0709876543209878e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\special_tokens_map.json\n",
      " 68%|██████▊   | 2625/3888 [57:13<23:06,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.61 | 81.27 | 73.97 | 82.69 | 79.34 |    78.91     |      71.73      | 76.79 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.78875 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2800/3888 [1:01:04<20:31,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.31 | 81.29 | 73.97 | 82.69 | 79.23 |    78.81     |      71.62      | 76.70 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.70250000000001 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2975/3888 [1:04:54<16:28,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.12 | 81.21 | 73.89 | 82.67 | 79.11 |    78.77     |      71.74      | 76.64 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.64375 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3000/3888 [1:06:00<15:50,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0045, 'learning_rate': 6.851851851851852e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\special_tokens_map.json\n",
      " 81%|████████  | 3150/3888 [1:08:45<13:17,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.23 | 81.05 | 73.78 | 82.57 | 78.89 |    78.52     |      71.58      | 76.52 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.5175 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 3325/3888 [1:12:33<10:04,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.14 | 80.93 | 73.77 | 82.47 | 78.82 |    78.45     |      71.45      | 76.43 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.4325 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3500/3888 [1:16:23<07:06,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0039, 'learning_rate': 2.9938271604938273e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.24 | 80.88 | 73.69 | 82.45 | 78.91 |    78.48     |      71.46      | 76.44 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.44375 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\special_tokens_map.json\n",
      " 95%|█████████▍| 3675/3888 [1:20:15<03:51,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.20 | 80.93 | 73.71 | 82.44 | 78.99 |    78.49     |      71.45      | 76.46 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.45875000000001 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3850/3888 [1:24:03<00:42,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.19 | 80.89 | 73.67 | 82.46 | 78.99 |    78.48     |      71.46      | 76.45 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.44875 \n",
      "max acc  76.83749999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3888/3888 [1:25:23<00:00,  1.10s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 3888/3888 [1:25:23<00:00,  1.32s/it]\n",
      "loading configuration file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\config.json\n",
      "Model config BertConfig {\n",
      "  \"K\": 512,\n",
      "  \"K_start\": 128,\n",
      "  \"age_test\": false,\n",
      "  \"architectures\": [\n",
      "    \"MoCoSEModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"contextual_wordembs_aug\": false,\n",
      "  \"ema_decay\": 0.75,\n",
      "  \"embedding_drop_prob\": 0.1,\n",
      "  \"feature_drop_prob\": 0,\n",
      "  \"fgsm\": 5e-09,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mlp_layers\": 2,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"neg_queue_slice_span\": 256,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"out_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"proj_layers\": 1,\n",
      "  \"token_drop_prob\": 0,\n",
      "  \"token_shuffle\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"untokenizer\": null,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5123.4284, 'train_samples_per_second': 194.293, 'train_steps_per_second': 0.759, 'train_loss': 0.20939416202252784, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing MoCoSEModel.\n",
      "\n",
      "All the weights of MoCoSEModel were initialized from the model checkpoint at F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MoCoSEModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------alignment & uniformity-----------------\n",
      "all_loader_align tensor(0.3321)\n",
      "pos_loader_align tensor(0.1304)\n",
      "all_loader_uniformity tensor(-1.5858)\n",
      "pos_loader_uniformity tensor(-1.6468)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "model_ = MoCoSEModel.from_pretrained('F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\best-model')\n",
    "model_ = model_.cuda()\n",
    "align_all = get_align(model_, all_loader)\n",
    "align_pos = get_align(model_, pos_loader)\n",
    "uniform_all = get_unif(model_, all_loader)\n",
    "uniform_pos = get_unif(model_, pos_loader)\n",
    "\n",
    "all_loader_align = sum(align_all)/len(align_all)\n",
    "pos_loader_align = sum(align_pos)/len(align_pos)\n",
    "\n",
    "all_loader_uniformity = sum(uniform_all)/len(uniform_all)\n",
    "pos_loader_uniformity = sum(uniform_pos)/len(uniform_pos)\n",
    "print(\"--------------alignment & uniformity-----------------\")\n",
    "print(\"all_loader_align\",all_loader_align)\n",
    "print(\"pos_loader_align\",pos_loader_align)\n",
    "print(\"all_loader_uniformity\",all_loader_uniformity)\n",
    "print(\"pos_loader_uniformity\",pos_loader_uniformity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f122a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 995447\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3888\n",
      "  5%|▍         | 175/3888 [03:12<1:09:38,  1.13s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 28.80 | 52.23 | 41.51 | 53.05 | 57.12 |    31.06     |      47.52      | 44.47 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 44.47 \n",
      "max acc  44.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 350/3888 [07:08<1:07:09,  1.14s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 52.06 | 67.19 | 57.39 | 70.63 | 68.16 |    57.48     |      66.21      | 62.73 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 62.731249999999996 \n",
      "max acc  62.731249999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3888 [10:38<1:02:51,  1.11s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3094, 'learning_rate': 2.6141975308641973e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\special_tokens_map.json\n",
      " 14%|█▎        | 525/3888 [11:08<1:01:27,  1.10s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 56.68 | 71.92 | 63.17 | 75.15 | 71.58 |    64.73     |      69.82      | 67.58 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 67.57875 \n",
      "max acc  67.57875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 700/3888 [15:02<59:01,  1.11s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 59.91 | 74.59 | 66.34 | 77.40 | 74.02 |    68.62     |      71.58      | 70.35 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 70.35125 \n",
      "max acc  70.35125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 875/3888 [18:56<55:26,  1.10s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 61.49 | 75.91 | 68.25 | 78.51 | 75.25 |    71.36     |      72.36      | 71.88 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 71.87625 \n",
      "max acc  71.87625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3888 [21:59<54:46,  1.14s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0177, 'learning_rate': 2.2283950617283953e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\special_tokens_map.json\n",
      " 27%|██▋       | 1050/3888 [22:58<53:47,  1.14s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 62.35 | 76.97 | 69.27 | 79.39 | 76.34 |    72.83     |      72.25      | 72.77 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 72.77125 \n",
      "max acc  72.77125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1225/3888 [26:56<49:50,  1.12s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 64.17 | 78.07 | 70.39 | 80.21 | 77.10 |    74.70     |      72.13      | 73.82 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 73.82374999999999 \n",
      "max acc  73.82374999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1400/3888 [30:53<46:20,  1.12s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.00 | 78.83 | 70.95 | 80.85 | 77.47 |    75.85     |      72.38      | 74.48 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 74.47625000000001 \n",
      "max acc  74.47625000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1500/3888 [33:26<44:17,  1.11s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0093, 'learning_rate': 1.8425925925925926e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\special_tokens_map.json\n",
      " 41%|████      | 1575/3888 [34:52<43:59,  1.14s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 66.32 | 79.41 | 71.68 | 81.52 | 77.99 |    77.05     |      72.14      | 75.16 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 75.15875 \n",
      "max acc  75.15875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1750/3888 [38:54<42:01,  1.18s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 66.81 | 79.69 | 72.15 | 81.78 | 78.34 |    77.52     |      72.07      | 75.48 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 75.47999999999999 \n",
      "max acc  75.47999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1925/3888 [42:49<37:05,  1.13s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 67.86 | 80.38 | 72.79 | 82.21 | 78.70 |    78.28     |      71.97      | 76.03 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.0275 \n",
      "max acc  76.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 2000/3888 [44:54<35:24,  1.13s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0062, 'learning_rate': 1.4567901234567902e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\special_tokens_map.json\n",
      " 54%|█████▍    | 2100/3888 [46:49<32:41,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.63 | 80.88 | 73.49 | 82.50 | 78.92 |    78.67     |      71.82      | 76.42 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.41625 \n",
      "max acc  76.41625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 2275/3888 [50:44<30:11,  1.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.43 | 80.88 | 73.47 | 82.48 | 78.95 |    78.69     |      71.84      | 76.39 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.39125 \n",
      "max acc  76.41625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2450/3888 [54:36<26:19,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.81 | 81.00 | 73.74 | 82.76 | 79.02 |    78.83     |      71.76      | 76.56 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.56 \n",
      "max acc  76.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2500/3888 [56:11<24:57,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0047, 'learning_rate': 1.0709876543209878e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\special_tokens_map.json\n",
      " 68%|██████▊   | 2625/3888 [58:30<23:57,  1.14s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.41 | 81.41 | 74.10 | 83.01 | 79.10 |    79.22     |      71.55      | 76.83 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.82875 \n",
      "max acc  76.82875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2800/3888 [1:02:22<19:24,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.26 | 81.52 | 74.10 | 83.02 | 79.12 |    79.14     |      71.52      | 76.81 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.81125 \n",
      "max acc  76.82875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2975/3888 [1:06:12<16:26,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.18 | 81.63 | 74.18 | 82.98 | 79.20 |    79.20     |      71.58      | 76.85 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.85000000000001 \n",
      "max acc  76.85000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3000/3888 [1:07:20<16:24,  1.11s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.004, 'learning_rate': 6.851851851851852e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\special_tokens_map.json\n",
      " 81%|████████  | 3150/3888 [1:10:08<13:29,  1.10s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.28 | 81.61 | 74.13 | 83.02 | 79.20 |    79.21     |      71.53      | 76.85 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.85374999999999 \n",
      "max acc  76.85374999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 3325/3888 [1:14:01<10:21,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.45 | 81.60 | 74.24 | 83.04 | 79.21 |    79.21     |      71.48      | 76.89 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.89 \n",
      "max acc  76.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3500/3888 [1:17:53<07:06,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0033, 'learning_rate': 2.9938271604938273e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.44 | 81.57 | 74.25 | 83.00 | 79.19 |    79.15     |      71.50      | 76.87 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.87125 \n",
      "max acc  76.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\special_tokens_map.json\n",
      " 95%|█████████▍| 3675/3888 [1:21:47<03:52,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.44 | 81.55 | 74.23 | 82.97 | 79.22 |    79.15     |      71.50      | 76.87 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.86625000000001 \n",
      "max acc  76.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3850/3888 [1:25:38<00:41,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.45 | 81.50 | 74.22 | 82.99 | 79.22 |    79.15     |      71.49      | 76.86 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.86 \n",
      "max acc  76.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3888/3888 [1:26:58<00:00,  1.09s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 3888/3888 [1:26:58<00:00,  1.34s/it]\n",
      "loading configuration file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\config.json\n",
      "Model config BertConfig {\n",
      "  \"K\": 256,\n",
      "  \"K_start\": 128,\n",
      "  \"age_test\": false,\n",
      "  \"architectures\": [\n",
      "    \"MoCoSEModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"contextual_wordembs_aug\": false,\n",
      "  \"ema_decay\": 0.85,\n",
      "  \"embedding_drop_prob\": 0.1,\n",
      "  \"feature_drop_prob\": 0,\n",
      "  \"fgsm\": 5e-09,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mlp_layers\": 2,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"neg_queue_slice_span\": 256,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"out_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"proj_layers\": 1,\n",
      "  \"token_drop_prob\": 0,\n",
      "  \"token_shuffle\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"untokenizer\": null,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5218.4244, 'train_samples_per_second': 190.756, 'train_steps_per_second': 0.745, 'train_loss': 0.1745365717651422, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing MoCoSEModel.\n",
      "\n",
      "All the weights of MoCoSEModel were initialized from the model checkpoint at F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MoCoSEModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------alignment & uniformity-----------------\n",
      "all_loader_align tensor(0.3453)\n",
      "pos_loader_align tensor(0.1367)\n",
      "all_loader_uniformity tensor(-1.6391)\n",
      "pos_loader_uniformity tensor(-1.7004)\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "config.out_size=768\n",
    "config.mlp_layers=2\n",
    "config.proj_layers=1\n",
    "\n",
    "config.fgsm = 5e-9\n",
    "config.embedding_drop_prob = 0.1\n",
    "config.token_drop_prob = 0\n",
    "config.feature_drop_prob = 0\n",
    "config.token_shuffle = False\n",
    "config.contextual_wordembs_aug = False\n",
    "\n",
    "config.age_test = False\n",
    "\n",
    "config.K = 256\n",
    "config.K_start = 128\n",
    "config.ema_decay = 0.85\n",
    "\n",
    "\n",
    "config.neg_queue_slice_span = 256 # euqal to batch size, won't work if age_test=False\n",
    "\n",
    "with open(r'F:\\Experiment\\MoCoSE\\codes\\pretrained_bert\\bert-base-uncased\\vocab.txt','r',encoding='utf8') as f:\n",
    "    test_untokenizer = f.readlines()\n",
    "untokenizer = [i[:-1] for i in test_untokenizer]\n",
    "config.untokenizer = None\n",
    "\n",
    "model = MoCoSEModel(config)\n",
    "model.online_embeddings.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\embeddings.pth'))\n",
    "model.online_encoder.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\encoder.pth'))\n",
    "model.online_pooler.dense.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\pooler_dense.pth'))\n",
    "\n",
    "model.prepare()\n",
    "model = model.cuda()\n",
    "\n",
    "non_optimizer_list = [model.target_encoder,model.target_pooler]\n",
    "for layer in non_optimizer_list:\n",
    "    for para in layer.parameters():\n",
    "        para.requires_grad = False\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = 'F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\',\n",
    "    evaluation_strategy   = \"steps\",\n",
    "    eval_steps            = 175,\n",
    "    learning_rate         = 3e-5,\n",
    "    num_train_epochs      = 1.0,\n",
    "    weight_decay          = 1e-6,\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size  = 256,\n",
    "    dataloader_drop_last = True,\n",
    ")\n",
    "trainer = MoCoSETrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model_ = MoCoSEModel.from_pretrained('F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\best-model')\n",
    "model_ = model_.cuda()\n",
    "align_all = get_align(model_, all_loader)\n",
    "align_pos = get_align(model_, pos_loader)\n",
    "uniform_all = get_unif(model_, all_loader)\n",
    "uniform_pos = get_unif(model_, pos_loader)\n",
    "\n",
    "all_loader_align = sum(align_all)/len(align_all)\n",
    "pos_loader_align = sum(align_pos)/len(align_pos)\n",
    "\n",
    "all_loader_uniformity = sum(uniform_all)/len(uniform_all)\n",
    "pos_loader_uniformity = sum(uniform_pos)/len(uniform_pos)\n",
    "print(\"--------------alignment & uniformity-----------------\")\n",
    "print(\"all_loader_align\",all_loader_align)\n",
    "print(\"pos_loader_align\",pos_loader_align)\n",
    "print(\"all_loader_uniformity\",all_loader_uniformity)\n",
    "print(\"pos_loader_uniformity\",pos_loader_uniformity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbad010",
   "metadata": {},
   "source": [
    "##### supplementary experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791443e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\config.json\n",
      "Model config BertConfig {\n",
      "  \"K\": 256,\n",
      "  \"K_start\": 128,\n",
      "  \"age_test\": false,\n",
      "  \"architectures\": [\n",
      "    \"MoCoSEModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"contextual_wordembs_aug\": false,\n",
      "  \"ema_decay\": 0.75,\n",
      "  \"embedding_drop_prob\": 0.1,\n",
      "  \"feature_drop_prob\": 0,\n",
      "  \"fgsm\": 5e-09,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"mlp_layers\": 2,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"neg_queue_slice_span\": 256,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"out_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"proj_layers\": 1,\n",
      "  \"token_drop_prob\": 0,\n",
      "  \"token_shuffle\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"untokenizer\": null,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MoCoSEModel.\n",
      "\n",
      "All the weights of MoCoSEModel were initialized from the model checkpoint at F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\best-model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MoCoSEModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------alignment & uniformity-----------------\n",
      "all_loader_align tensor(0.4324)\n",
      "pos_loader_align tensor(0.1747)\n",
      "all_loader_uniformity tensor(-2.0205)\n",
      "pos_loader_uniformity tensor(-2.0943)\n"
     ]
    }
   ],
   "source": [
    "model_ = MoCoSEModel.from_pretrained('F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\best-model')\n",
    "model_ = model_.cuda()\n",
    "align_all = get_align(model_, all_loader)\n",
    "align_pos = get_align(model_, pos_loader)\n",
    "uniform_all = get_unif(model_, all_loader)\n",
    "uniform_pos = get_unif(model_, pos_loader)\n",
    "\n",
    "all_loader_align = sum(align_all)/len(align_all)\n",
    "pos_loader_align = sum(align_pos)/len(align_pos)\n",
    "\n",
    "all_loader_uniformity = sum(uniform_all)/len(uniform_all)\n",
    "pos_loader_uniformity = sum(uniform_pos)/len(uniform_pos)\n",
    "print(\"--------------alignment & uniformity-----------------\")\n",
    "print(\"all_loader_align\",all_loader_align)\n",
    "print(\"pos_loader_align\",pos_loader_align)\n",
    "print(\"all_loader_uniformity\",all_loader_uniformity)\n",
    "print(\"pos_loader_uniformity\",pos_loader_uniformity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636ee5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36907eae",
   "metadata": {},
   "source": [
    "### Text augumentation experiment (ContextualWordEmbsAug, SpellingAug, ContextualWordEmbsForSentenceAug, BackTranslationAug(en<->de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bfd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk #, load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from mocose import *\n",
    "from transformers import BertConfig\n",
    "from mocose_tools import MoCoSETrainer\n",
    "from transformers.trainer import TrainingArguments\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_size = 64\n",
    "train_dataset = load_from_disk(\"F:\\\\Models\\\\temp\\\\wiki_for_sts_32\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980114d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 995447\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3888\n",
      "  5%|▍         | 175/3888 [1:01:03<22:06:16, 21.43s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 45.35 | 47.54 | 35.09 | 56.65 | 55.83 |    39.74     |      50.33      | 47.22 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 47.21875 \n",
      "max acc  47.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 350/3888 [2:02:58<19:44:47, 20.09s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 44.88 | 48.71 | 33.94 | 53.96 | 56.24 |    42.92     |      56.72      | 48.20 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 48.19625 \n",
      "max acc  48.19625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3888 [2:54:56<18:52:16, 20.05s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3487, 'learning_rate': 2.6141975308641973e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\special_tokens_map.json\n",
      " 14%|█▎        | 525/3888 [3:03:34<19:58:06, 21.38s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 48.41 | 53.76 | 38.57 | 59.30 | 60.05 |    50.75     |      61.48      | 53.19 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 53.18875 \n",
      "max acc  53.18875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 700/3888 [4:04:03<18:00:43, 20.34s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 49.83 | 56.68 | 40.92 | 60.53 | 60.91 |    52.97     |      61.68      | 54.79 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 54.78875000000001 \n",
      "max acc  54.78875000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 875/3888 [5:04:37<16:49:54, 20.11s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 51.13 | 59.57 | 42.78 | 61.40 | 62.15 |    54.99     |      62.29      | 56.33 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 56.330000000000005 \n",
      "max acc  56.330000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3888 [5:47:58<16:42:45, 20.83s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0853, 'learning_rate': 2.2283950617283953e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\special_tokens_map.json\n",
      " 27%|██▋       | 1050/3888 [6:05:07<16:08:07, 20.47s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 50.81 | 61.20 | 43.87 | 62.24 | 62.51 |    55.28     |      62.35      | 56.89 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 56.89375 \n",
      "max acc  56.89375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1225/3888 [7:05:29<15:35:31, 21.08s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 51.57 | 62.39 | 45.01 | 63.10 | 64.22 |    56.31     |      61.95      | 57.79 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 57.7925 \n",
      "max acc  57.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1400/3888 [8:06:14<14:16:51, 20.66s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 51.74 | 63.12 | 45.42 | 63.75 | 64.24 |    56.48     |      62.51      | 58.18 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 58.18 \n",
      "max acc  58.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1500/3888 [8:41:14<13:39:43, 20.60s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0376, 'learning_rate': 1.8425925925925926e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\special_tokens_map.json\n",
      " 41%|████      | 1575/3888 [9:07:19<13:31:39, 21.05s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 53.61 | 65.48 | 48.83 | 65.92 | 66.08 |    59.00     |      64.24      | 60.45 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 60.45125 \n",
      "max acc  60.45125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1750/3888 [10:08:38<12:54:33, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 52.11 | 62.72 | 45.10 | 64.11 | 63.37 |    56.50     |      62.40      | 58.04 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 58.04375 \n",
      "max acc  60.45125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1925/3888 [11:09:49<10:35:42, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 52.98 | 63.64 | 46.40 | 64.78 | 63.87 |    57.09     |      62.54      | 58.76 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 58.7575 \n",
      "max acc  60.45125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 2000/3888 [11:36:19<10:55:52, 20.84s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0285, 'learning_rate': 1.4567901234567902e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\special_tokens_map.json\n",
      " 54%|█████▍    | 2091/3888 [12:07:54<10:25:48, 20.90s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24628/232813897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m                 if (\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1847\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Experiment\\MoCoSE\\codes\\model\\mocose.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, sent_emb)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[0mtemp_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_origin_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muntokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[1;31m#temp_sent = [tokenizer_func(aug_text_func(untokenizer,sent,aug)) for sent in temp_ids]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mtemp_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maug_and_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m                 \u001b[0maug_input_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[0maug_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Experiment\\MoCoSE\\codes\\model\\mocose.py\u001b[0m in \u001b[0;36maug_and_tokenizer\u001b[1;34m(tokenizer, origin_sts, aug_model)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maug_and_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin_sts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maug_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[0maug_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maug_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_sts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[0maug_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max_length'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtruncation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maug_tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\base_augmenter.py\u001b[0m in \u001b[0;36maugment\u001b[1;34m(self, data, n, num_thread)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'AbstSummAug'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BackTranslationAug'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ContextualWordEmbsAug'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ContextualWordEmbsForSentenceAug'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_fx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                         \u001b[0maugmented_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\augmenter\\sentence\\context_word_embs_sentence.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_custom_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_custom_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_native_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\augmenter\\sentence\\context_word_embs_sentence.py\u001b[0m in \u001b[0;36m_custom_insert\u001b[1;34m(self, all_data)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             outputs = self.model.predict(texts, n=1, external_memory=external_memory, \n\u001b[0m\u001b[0;32m    153\u001b[0m                 include_punctuation=True)\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\model\\lang_models\\xlnet.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, texts, target_words, n, external_memory, include_punctuation)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mtarget_token_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_token_idxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiltering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_token_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_token_idxes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 new_tokens = self.pick(target_token_logits, target_token_idxes, target_word=target_token, \n\u001b[0m\u001b[0;32m    139\u001b[0m                     n=10, include_punctuation=include_punctuation)\n\u001b[0;32m    140\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\model\\lang_models\\language_models.py\u001b[0m in \u001b[0;36mpick\u001b[1;34m(self, logits, idxes, target_word, n, include_punctuation)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_punctuation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mcandidate_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_multinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[0mcandidate_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0midxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcandidate_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcandidate_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcandidate_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         results = self.get_candidiates(candidate_ids, candidate_probas, target_word, n, \n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\nlpaug\\model\\lang_models\\language_models.py\u001b[0m in \u001b[0;36mprob_multinomial\u001b[1;34m(self, logits, n)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Draw candidates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mnum_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Number of potential candidate is small when top_k/ top_p are used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mfiltered_top_n_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'return_proba'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "config.out_size=768\n",
    "config.mlp_layers=2\n",
    "config.proj_layers=1\n",
    "\n",
    "config.fgsm = 0 #5e-9\n",
    "config.embedding_drop_prob = 0.1\n",
    "config.token_drop_prob = 0\n",
    "config.feature_drop_prob = 0\n",
    "config.token_shuffle = False\n",
    "config.contextual_wordembs_aug = True\n",
    "\n",
    "config.age_test = False\n",
    "\n",
    "config.K = 512\n",
    "config.K_start = 128\n",
    "config.ema_decay = 0.85\n",
    "\n",
    "# 'cwea' : ContextualWordEmbsAug  roberta-base\n",
    "# 'spa'  : SpellingAug\n",
    "# 'cwesa': ContextualWordEmbsForSentenceAug  xlnet-base-cased\n",
    "# 'bta'  : BackTranslationAug  facebook/wmt19-en-de  to  facebook/wmt19-de-en\n",
    "config.text_aug_type = 'cwesa' # won't work if contextual_wordembs_aug=False\n",
    "\n",
    "config.neg_queue_slice_span = 256 # euqal to batch size, won't work if age_test=False\n",
    "\n",
    "model = MoCoSEModel(config)\n",
    "model.online_embeddings.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\embeddings.pth'))\n",
    "model.online_encoder.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\encoder.pth'))\n",
    "model.online_pooler.dense.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\pooler_dense.pth'))\n",
    "\n",
    "model.prepare()\n",
    "model = model.cuda()\n",
    "\n",
    "non_optimizer_list = [model.target_encoder,model.target_pooler]\n",
    "for layer in non_optimizer_list:\n",
    "    for para in layer.parameters():\n",
    "        para.requires_grad = False\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = 'F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\',\n",
    "    evaluation_strategy   = \"steps\",\n",
    "    eval_steps            = 175,\n",
    "    learning_rate         = 3e-5,\n",
    "    num_train_epochs      = 1.0,\n",
    "    weight_decay          = 1e-6,\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size  = 256,\n",
    "    dataloader_drop_last = True,\n",
    ")\n",
    "trainer = MoCoSETrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7ef8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b5e3de",
   "metadata": {},
   "source": [
    "########################## fgsm #######################\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 69.88 | 81.24 | 73.51 | 82.78 | 79.24 |    78.65     |      71.88      | 76.74 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "68%|██████▊   | 2625/3888 [57:18<22:43,  1.08s/it]\n",
    "acc before pooler: 76.74 \n",
    "max acc  76.74\n",
    "\n",
    "\n",
    "########################## fgsm + contextual_wordembs_aug #######################\n",
    "\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 34.16 | 45.32 | 29.42 | 48.31 | 42.15 |    31.64     |      42.70      | 39.10 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 39.1 \n",
    "max acc  39.49125\n",
    "100%|██████████| 3888/3888 [6:24:31<00:00,  5.61s/it]\n",
    "\n",
    "\n",
    "########################## contextual_wordembs_aug 'roberta-base' #######################\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 26.17 | 31.45 | 19.77 | 39.83 | 30.31 |    21.52     |      31.87      | 28.70 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 28.7025 \n",
    "max acc  28.7025\n",
    "结束时，avg仍然在增长\n",
    "\n",
    "\n",
    "########################## SpellingAug mistake words #######################\n",
    "67%|██████▋   | 2600/3888 [1:35:21<43:54,  2.05s/it]\n",
    "+-------+-------+-------+------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 13.53 | 25.69 | 11.77 | 25.35 | 31.42 |    11.17     |      21.75      | 20.10 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 20.0975 \n",
    "max acc  22.320000000000004\n",
    "\n",
    "\n",
    "########################## fgsm + SpellingAug mistake words #######################\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 20.46 | 20.09 | 10.86 | 23.76 | 33.25 |    16.40     |      26.80      | 21.66 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 21.66 \n",
    "max acc  21.66\n",
    "\n",
    "\n",
    "############# ContextualWordEmbsForSentenceAug 'xlnet-base-cased' ###########\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 53.61 | 65.48 | 48.83 | 65.92 | 66.08 |    59.00     |      64.24      | 60.45 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 60.45125 \n",
    "max acc  60.45125\n",
    "\n",
    "\n",
    "############# fgsm + ContextualWordEmbsForSentenceAug 'xlnet-base-cased' ####\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 52.71 | 64.84 | 48.18 | 66.24 | 66.72 |    59.13     |      63.54      | 60.19 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 60.19375000000001 \n",
    "max acc  60.19375000000001\n",
    "\n",
    "\n",
    "########################## backtranslation en->de->en #######################\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 61.54 | 71.66 | 62.87 | 75.80 | 73.17 |    71.45     |      68.03      | 69.22 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 69.2175 \n",
    "max acc  69.3475\n",
    "96%|█████████▌| 3731/3888 [14:01:11<40:34, 15.51s/it]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753b29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk #, load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from mocose import *\n",
    "from transformers import BertConfig\n",
    "from mocose_tools import MoCoSETrainer\n",
    "from transformers.trainer import TrainingArguments\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "batch_size = 64\n",
    "train_dataset = load_from_disk(\"F:\\\\Models\\\\temp\\\\wiki_for_sts_32\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152dad57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 995447\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3888\n",
      "  5%|▍         | 175/3888 [03:16<1:08:05,  1.10s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 32.03 | 59.50 | 45.95 | 58.52 | 59.63 |    35.21     |      53.16      | 49.14 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 49.1425 \n",
      "max acc  49.1425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 350/3888 [07:06<1:04:47,  1.10s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 55.10 | 72.56 | 60.18 | 71.77 | 70.56 |    61.99     |      67.09      | 65.61 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 65.6075 \n",
      "max acc  65.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3888 [10:29<1:00:39,  1.07s/it] Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3013, 'learning_rate': 2.6141975308641973e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-500\\special_tokens_map.json\n",
      " 14%|█▎        | 525/3888 [10:59<1:01:56,  1.11s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 61.40 | 76.52 | 65.44 | 76.22 | 74.22 |    69.52     |      70.11      | 70.49 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 70.49 \n",
      "max acc  70.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 700/3888 [14:48<57:08,  1.08s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 62.34 | 77.67 | 66.80 | 77.11 | 75.53 |    71.57     |      70.58      | 71.66 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 71.6575 \n",
      "max acc  71.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 875/3888 [18:38<54:08,  1.08s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 64.87 | 79.16 | 68.87 | 79.09 | 77.10 |    74.18     |      71.63      | 73.56 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 73.5575 \n",
      "max acc  73.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3888 [21:35<51:57,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0183, 'learning_rate': 2.2283950617283953e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1000\\special_tokens_map.json\n",
      " 27%|██▋       | 1050/3888 [22:32<50:24,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.38 | 80.17 | 70.13 | 79.92 | 77.92 |    75.07     |      71.68      | 74.32 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 74.32374999999999 \n",
      "max acc  74.32374999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1225/3888 [26:21<49:24,  1.11s/it]   Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 65.68 | 80.46 | 70.52 | 80.43 | 78.14 |    75.80     |      71.80      | 74.69 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 74.69 \n",
      "max acc  74.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1400/3888 [30:18<44:52,  1.08s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 66.68 | 81.07 | 71.54 | 81.23 | 78.68 |    76.74     |      71.77      | 75.39 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 75.3875 \n",
      "max acc  75.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1500/3888 [32:49<43:53,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0097, 'learning_rate': 1.8425925925925926e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-1500\\special_tokens_map.json\n",
      " 41%|████      | 1575/3888 [34:13<42:30,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 67.66 | 81.44 | 72.35 | 81.83 | 78.98 |    77.53     |      71.80      | 75.94 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 75.94125 \n",
      "max acc  75.94125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1750/3888 [38:05<38:02,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.13 | 81.75 | 72.99 | 82.17 | 79.07 |    77.75     |      71.71      | 76.22 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.22375000000001 \n",
      "max acc  76.22375000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1925/3888 [41:54<35:53,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.33 | 81.90 | 73.19 | 82.24 | 79.28 |    77.81     |      71.74      | 76.36 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.35625 \n",
      "max acc  76.35625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 2000/3888 [43:54<34:29,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0067, 'learning_rate': 1.4567901234567902e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2000\\special_tokens_map.json\n",
      " 54%|█████▍    | 2100/3888 [45:46<32:26,  1.09s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.36 | 82.05 | 73.46 | 82.17 | 79.28 |    77.77     |      71.75      | 76.41 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.40625 \n",
      "max acc  76.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 2275/3888 [49:38<29:01,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.52 | 81.93 | 73.40 | 82.14 | 79.16 |    77.70     |      71.65      | 76.36 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.3575 \n",
      "max acc  76.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2450/3888 [53:25<25:41,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.38 | 81.67 | 73.18 | 82.06 | 79.06 |    77.59     |      71.62      | 76.22 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.22250000000001 \n",
      "max acc  76.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2500/3888 [54:58<25:31,  1.10s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0052, 'learning_rate': 1.0709876543209878e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-2500\\special_tokens_map.json\n",
      " 68%|██████▊   | 2625/3888 [57:16<22:45,  1.08s/it]Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 69.03 | 81.99 | 73.67 | 82.25 | 79.25 |    77.88     |      71.61      | 76.53 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\\\best-model\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc before pooler: 76.52624999999999 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2800/3888 [1:01:07<19:39,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.85 | 81.98 | 73.57 | 82.24 | 79.21 |    77.85     |      71.47      | 76.45 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.4525 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2975/3888 [1:04:57<16:10,  1.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.59 | 81.84 | 73.46 | 82.20 | 79.12 |    77.65     |      71.48      | 76.33 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.33375000000001 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3000/3888 [1:06:02<15:52,  1.07s/it]  Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0046, 'learning_rate': 6.851851851851852e-06, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3000\\special_tokens_map.json\n",
      " 81%|████████  | 3150/3888 [1:08:45<13:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.71 | 81.80 | 73.43 | 82.23 | 79.10 |    77.70     |      71.42      | 76.34 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.34125 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 3325/3888 [1:12:32<10:04,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.40 | 81.76 | 73.32 | 82.18 | 79.11 |    77.62     |      71.30      | 76.24 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.24125000000001 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3500/3888 [1:16:19<06:53,  1.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0039, 'learning_rate': 2.9938271604938273e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\n",
      "Configuration saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.44 | 81.61 | 73.27 | 82.17 | 79.15 |    77.61     |      71.27      | 76.22 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.2175 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in F:\\Experiment\\MoCoSE\\codes\\trained_models\\mocose_base_out\\checkpoint-3500\\special_tokens_map.json\n",
      " 95%|█████████▍| 3675/3888 [1:20:08<03:48,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.42 | 81.70 | 73.30 | 82.16 | 79.16 |    77.65     |      71.24      | 76.23 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.2325 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3850/3888 [1:23:54<00:40,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 68.39 | 81.69 | 73.31 | 82.20 | 79.17 |    77.67     |      71.25      | 76.24 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "acc before pooler: 76.24000000000001 \n",
      "max acc  76.52624999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3888/3888 [1:25:14<00:00,  1.07s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 3888/3888 [1:25:14<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5114.5801, 'train_samples_per_second': 194.629, 'train_steps_per_second': 0.76, 'train_loss': 0.17397870236831436, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3888, training_loss=0.17397870236831436, metrics={'train_runtime': 5114.5801, 'train_samples_per_second': 194.629, 'train_steps_per_second': 0.76, 'train_loss': 0.17397870236831436, 'epoch': 1.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "config.out_size=768\n",
    "config.mlp_layers=2\n",
    "config.proj_layers=1\n",
    "\n",
    "config.fgsm = 0 #5e-9\n",
    "config.embedding_drop_prob = 0.1\n",
    "config.token_drop_prob = 0\n",
    "config.feature_drop_prob = 0\n",
    "config.token_shuffle = False\n",
    "config.contextual_wordembs_aug = False\n",
    "\n",
    "config.age_test = True\n",
    "\n",
    "config.K = 1024\n",
    "config.K_start = 128\n",
    "config.ema_decay = 0.85\n",
    "\n",
    "# 'cwea' : ContextualWordEmbsAug  roberta-base\n",
    "# 'spa'  : SpellingAug\n",
    "# 'cwesa': ContextualWordEmbsForSentenceAug  xlnet-base-cased\n",
    "# 'bta'  : BackTranslationAug  facebook/wmt19-en-de  to  facebook/wmt19-de-en\n",
    "config.text_aug_type = 'cwesa' # won't work if contextual_wordembs_aug=False\n",
    "\n",
    "config.neg_queue_slice_span = 256 # euqal to batch size, won't work if age_test=False\n",
    "\n",
    "model = MoCoSEModel(config)\n",
    "model.online_embeddings.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\embeddings.pth'))\n",
    "model.online_encoder.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\encoder.pth'))\n",
    "model.online_pooler.dense.load_state_dict(torch.load('F:\\\\Models\\\\temp\\\\bert-base-uncased-weights\\\\pooler_dense.pth'))\n",
    "\n",
    "model.prepare()\n",
    "model = model.cuda()\n",
    "\n",
    "non_optimizer_list = [model.target_encoder,model.target_pooler]\n",
    "for layer in non_optimizer_list:\n",
    "    for para in layer.parameters():\n",
    "        para.requires_grad = False\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = 'F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose_base_out\\\\',\n",
    "    evaluation_strategy   = \"steps\",\n",
    "    eval_steps            = 175,\n",
    "    learning_rate         = 3e-5,\n",
    "    num_train_epochs      = 1.0,\n",
    "    weight_decay          = 1e-6,\n",
    "    per_device_train_batch_size = 256,\n",
    "    per_device_eval_batch_size  = 256,\n",
    "    dataloader_drop_last = True,\n",
    ")\n",
    "trainer = MoCoSETrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bc150",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73e91415",
   "metadata": {},
   "source": [
    "########################## The impact of negative samples at different locations in the queue on the model performance. #######################\n",
    "config.out_size=768\n",
    "config.mlp_layers=2\n",
    "config.proj_layers=1\n",
    "config.fgsm = 5e-9\n",
    "config.embedding_drop_prob = 0.1\n",
    "config.token_drop_prob = 0\n",
    "config.feature_drop_prob = 0\n",
    "config.token_shuffle = False\n",
    "config.contextual_wordembs_aug = False\n",
    "\n",
    "eval_steps            = 175,\n",
    "learning_rate         = 3e-5,\n",
    "num_train_epochs      = 1.0,\n",
    "weight_decay          = 1e-6,\n",
    "per_device_train_batch_size = 256,\n",
    "\n",
    "config.K = 1024\n",
    "config.K_start = 128\n",
    "config.ema_decay = 0.85\n",
    "----------------------------------------------------------------------------------\n",
    "after fill the queue:  0-4；1-5；2-6；3-7；4-8 \n",
    "|=128  []=1024\n",
    "[||----||]\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 68.52 | 80.62 | 73.37 | 82.31 | 79.07 |    78.06     |      71.31      | 76.18 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 76.18 \n",
    "max acc  76.18\n",
    "\n",
    "[||||----]\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 69.31 | 80.64 | 73.34 | 82.37 | 78.76 |    78.00     |      70.26      | 76.10 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 76.0975 \n",
    "max acc  76.10375\n",
    "\n",
    "[--||||--]\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 69.65 | 82.26 | 74.45 | 83.29 | 78.79 |    78.43     |      72.28      | 77.02 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 77.02125000000001 \n",
    "max acc  77.02125000000001\n",
    "\n",
    "[----||||]\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 67.91 | 80.54 | 72.10 | 81.12 | 78.77 |    77.55     |      72.01      | 75.71 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 75.71375 \n",
    "max acc  75.71375\n",
    "\n",
    "\n",
    "[||||||||]\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "| 69.61 | 81.22 | 73.99 | 83.23 | 79.27 |    78.74     |      71.93      | 76.86 |\n",
    "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
    "acc before pooler: 76.85625 \n",
    "max acc  76.86375000000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8407cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for i in trainer.get_queue_avg_list():\n",
    "    tt.append(i.detach().cpu().numpy().astype(float))\n",
    "k256 = copy.deepcopy(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdda2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for i in trainer.get_queue_avg_list():\n",
    "    tt.append(i.detach().cpu())\n",
    "k512 = copy.deepcopy(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f3b65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for i in trainer.get_queue_avg_list():\n",
    "    tt.append(i.detach().cpu())\n",
    "k1024 = copy.deepcopy(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143e77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for i in trainer.get_queue_avg_list():\n",
    "    tt.append(i.detach().cpu())\n",
    "k2048 = copy.deepcopy(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c78c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = []\n",
    "for i in trainer.get_queue_avg_list():\n",
    "    tt.append(i.detach().cpu())\n",
    "k4096 = copy.deepcopy(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "641ef323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"604.835pt\" height=\"373.841441pt\" viewBox=\"0 0 604.835 373.841441\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-01-05T15:45:00.880602</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 373.841441 \nL 604.835 373.841441 \nL 604.835 0 \nL 0 0 \nL 0 373.841441 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \nL 589.99 11.136797 \nL 31.99 11.136797 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(24.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 143.59 347.081597 \nL 143.59 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(135.945 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 255.19 347.081597 \nL 255.19 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(247.545 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 366.79 347.081597 \nL 366.79 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(359.145 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 478.39 347.081597 \nL 478.39 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(470.745 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(582.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 351.018394)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 31.99 279.892637 \nL 589.99 279.892637 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 283.829434)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 31.99 212.703677 \nL 589.99 212.703677 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 216.640474)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 31.99 145.514717 \nL 589.99 145.514717 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 149.451514)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 31.99 78.325757 \nL 589.99 78.325757 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 82.262554)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" clip-path=\"url(#pe730bcc50b)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 15.073594)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe730bcc50b\">\n   <rect x=\"31.99\" y=\"11.136797\" width=\"558\" height=\"335.9448\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 15000x9270 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(list(zip(k256,k512,k1024,k2048,k4096)), dtype=float, columns = ['256','512','1024','2048','4096'])\n",
    "# ic(df.iloc[0])\n",
    "plt.figure(dpi=1500,figsize=(10,6.18))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.lineplot(data=df) #, x=\"per test iterations\", y=\"similarity score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "647f62e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"604.835pt\" height=\"373.841441pt\" viewBox=\"0 0 604.835 373.841441\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-01-05T15:45:01.043604</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 373.841441 \nL 604.835 373.841441 \nL 604.835 0 \nL 0 0 \nL 0 373.841441 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \nL 589.99 11.136797 \nL 31.99 11.136797 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(24.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 143.59 347.081597 \nL 143.59 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(135.945 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 255.19 347.081597 \nL 255.19 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(247.545 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 366.79 347.081597 \nL 366.79 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(359.145 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 478.39 347.081597 \nL 478.39 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(470.745 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(582.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 351.018394)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 31.99 279.892637 \nL 589.99 279.892637 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 283.829434)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 31.99 212.703677 \nL 589.99 212.703677 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 216.640474)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 31.99 145.514717 \nL 589.99 145.514717 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 149.451514)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 31.99 78.325757 \nL 589.99 78.325757 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 82.262554)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" clip-path=\"url(#pfc5cb37bf6)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 15.073594)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfc5cb37bf6\">\n   <rect x=\"31.99\" y=\"11.136797\" width=\"558\" height=\"335.9448\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 15000x9270 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(list(zip(k256,k512,k1024,k2048,k4096)), dtype=float, columns = ['256','512','1024','2048','4096'])\n",
    "# ic(df.iloc[0])\n",
    "plt.figure(dpi=1500,figsize=(10,6.18))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.lineplot(data=df) #, x=\"per test iterations\", y=\"similarity score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2118950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"604.835pt\" height=\"373.841441pt\" viewBox=\"0 0 604.835 373.841441\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-01-05T15:45:01.217606</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 373.841441 \nL 604.835 373.841441 \nL 604.835 0 \nL 0 0 \nL 0 373.841441 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \nL 589.99 11.136797 \nL 31.99 11.136797 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(24.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2e\" d=\"M 581 0 \nL 581 641 \nL 1222 641 \nL 1222 0 \nL 581 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 143.59 347.081597 \nL 143.59 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(135.945 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 255.19 347.081597 \nL 255.19 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(247.545 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-34\" d=\"M 2069 0 \nL 2069 1097 \nL 81 1097 \nL 81 1613 \nL 2172 4581 \nL 2631 4581 \nL 2631 1613 \nL 3250 1613 \nL 3250 1097 \nL 2631 1097 \nL 2631 0 \nL 2069 0 \nz\nM 2069 1613 \nL 2069 3678 \nL 634 1613 \nL 2069 1613 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 366.79 347.081597 \nL 366.79 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(359.145 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-36\" d=\"M 3184 3459 \nL 2625 3416 \nQ 2550 3747 2413 3897 \nQ 2184 4138 1850 4138 \nQ 1581 4138 1378 3988 \nQ 1113 3794 959 3422 \nQ 806 3050 800 2363 \nQ 1003 2672 1297 2822 \nQ 1591 2972 1913 2972 \nQ 2475 2972 2870 2558 \nQ 3266 2144 3266 1488 \nQ 3266 1056 3080 686 \nQ 2894 316 2569 119 \nQ 2244 -78 1831 -78 \nQ 1128 -78 684 439 \nQ 241 956 241 2144 \nQ 241 3472 731 4075 \nQ 1159 4600 1884 4600 \nQ 2425 4600 2770 4297 \nQ 3116 3994 3184 3459 \nz\nM 888 1484 \nQ 888 1194 1011 928 \nQ 1134 663 1356 523 \nQ 1578 384 1822 384 \nQ 2178 384 2434 671 \nQ 2691 959 2691 1453 \nQ 2691 1928 2437 2201 \nQ 2184 2475 1800 2475 \nQ 1419 2475 1153 2201 \nQ 888 1928 888 1484 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 478.39 347.081597 \nL 478.39 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(470.745 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-38\" d=\"M 1131 2484 \nQ 781 2613 612 2850 \nQ 444 3088 444 3419 \nQ 444 3919 803 4259 \nQ 1163 4600 1759 4600 \nQ 2359 4600 2725 4251 \nQ 3091 3903 3091 3403 \nQ 3091 3084 2923 2848 \nQ 2756 2613 2416 2484 \nQ 2838 2347 3058 2040 \nQ 3278 1734 3278 1309 \nQ 3278 722 2862 322 \nQ 2447 -78 1769 -78 \nQ 1091 -78 675 323 \nQ 259 725 259 1325 \nQ 259 1772 486 2073 \nQ 713 2375 1131 2484 \nz\nM 1019 3438 \nQ 1019 3113 1228 2906 \nQ 1438 2700 1772 2700 \nQ 2097 2700 2305 2904 \nQ 2513 3109 2513 3406 \nQ 2513 3716 2298 3927 \nQ 2084 4138 1766 4138 \nQ 1444 4138 1231 3931 \nQ 1019 3725 1019 3438 \nz\nM 838 1322 \nQ 838 1081 952 856 \nQ 1066 631 1291 507 \nQ 1516 384 1775 384 \nQ 2178 384 2440 643 \nQ 2703 903 2703 1303 \nQ 2703 1709 2433 1975 \nQ 2163 2241 1756 2241 \nQ 1359 2241 1098 1978 \nQ 838 1716 838 1322 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(582.345 364.455191)scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 351.018394)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 31.99 279.892637 \nL 589.99 279.892637 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 283.829434)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-32\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 31.99 212.703677 \nL 589.99 212.703677 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 216.640474)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-34\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 31.99 145.514717 \nL 589.99 145.514717 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 149.451514)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-36\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 31.99 78.325757 \nL 589.99 78.325757 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 82.262554)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-30\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-38\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" clip-path=\"url(#pa2f471c5db)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 15.073594)scale(0.11 -0.11)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-2e\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"83.398438\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 31.99 347.081597 \nL 31.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 589.99 347.081597 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 31.99 347.081597 \nL 589.99 347.081597 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 31.99 11.136797 \nL 589.99 11.136797 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa2f471c5db\">\n   <rect x=\"31.99\" y=\"11.136797\" width=\"558\" height=\"335.9448\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 15000x9270 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Times New Roman'\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df_cka = pd.DataFrame(trainer.getckalist())\n",
    "\n",
    "plt.figure(dpi=1500,figsize=(10,6.18))\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "sns.lineplot(data=df_cka)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2ce8c",
   "metadata": {},
   "source": [
    "# 2. Eval Model on STS Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c6a20",
   "metadata": {},
   "source": [
    "## Step 2.1. prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocose import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e733af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoCoSEModel.from_pretrained('F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\trained_models\\\\mocose-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01359ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabdd19",
   "metadata": {},
   "source": [
    "## Step 2.2 evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocose_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c72ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6537dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('F:\\\\Experiment\\\\MoCoSE\\\\codes\\\\pretrained_bert\\\\bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ecf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_acc = evalModel(model,tokenizer, pooler = 'cls_before_pooler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263c819",
   "metadata": {},
   "source": [
    "# 3. Eval Model on Transfer Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f1911",
   "metadata": {},
   "source": [
    "## step 3.1 prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocose import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c54014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoCoSEModel.from_pretrained('mocose-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c44aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13961b37",
   "metadata": {},
   "source": [
    "## Step 3.2 evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocose_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd90c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f34890",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('F:\\\\model\\\\bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b432d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_acc = evalTransferModel(model,tokenizer, pooler = 'cls_before_pooler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981befe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b44c525ca95e5dbf893da2282eb3ec3f420cb9fa59d94f9af90ca833dc1a37c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
